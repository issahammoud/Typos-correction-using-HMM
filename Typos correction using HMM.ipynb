{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Model (HMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train10.pkl\",\"rb\") as file:\n",
    "    train_10 = pk.load(file)\n",
    "\n",
    "with open(\"test10.pkl\",\"rb\") as file:\n",
    "    test_10 = pk.load(file)\n",
    "    \n",
    "with open(\"train20.pkl\",\"rb\") as file:\n",
    "    train_20 = pk.load(file)\n",
    "\n",
    "with open(\"test20.pkl\",\"rb\") as file:\n",
    "    test_20 = pk.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_10) = 29057\n",
      "len(test_10)  = 1501\n",
      "len(train_20) = 27184\n",
      "len(test_20)  = 3374\n"
     ]
    }
   ],
   "source": [
    "print(\"len(train_10) = {}\\nlen(test_10)  = {}\\nlen(train_20) = {}\\nlen(test_20)  = {}\"\\\n",
    "      .format(len(train_10),len(test_10),len(train_20),len(test_20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    \n",
    "    def __init__(self, train):\n",
    "        \n",
    "        flat = list(itertools.chain.from_iterable(train))\n",
    "        \n",
    "        self.state_list = np.unique([el[1] for el in flat])\n",
    "        self.N = len(self.state_list) # state_list length, just to verify that all alphabet appear\n",
    "        \n",
    "        self.obs_list = np.unique([el[0] for el in flat])\n",
    "        self.M = len(self.obs_list) # obs_list length, just to verify that all alphabet appear\n",
    "        \n",
    "        self.make_index(self.state_list, self.obs_list)\n",
    "        \n",
    "        self.init_state_proba = self.init_state_proba(train)\n",
    "        \n",
    "        self.emission_proba = self.emission_proba(train)\n",
    "        \n",
    "        self.trans_proba = self.trans_proba(train)\n",
    "        \n",
    "        self.trans_proba_2 = self.trans_proba_2(train)\n",
    "        \n",
    "    def make_index(self, state_list, obs_list):\n",
    "        \n",
    "        self.state_index = {}\n",
    "        self.obs_index = {}\n",
    "        self.index_obs = {}\n",
    "        \n",
    "        for i, el in enumerate(state_list):\n",
    "            self.state_index[el] = i\n",
    "            \n",
    "        for i, el in enumerate(obs_list):\n",
    "            self.obs_index[el] = i\n",
    "            self.index_obs[i] = el\n",
    "    \n",
    "    # initial state proba\n",
    "    def init_state_proba(self, train):\n",
    "        \n",
    "        pi = np.zeros(self.N)\n",
    "        \n",
    "        for el in train:\n",
    "            \n",
    "            pi[self.state_index[el[0][1]]] += 1\n",
    "            \n",
    "        return pi/np.sum(pi)\n",
    "    \n",
    "    # transition matrix for first order HMM\n",
    "    def trans_proba(self, train):\n",
    "        \n",
    "        A = np.zeros((self.N,self.N))\n",
    "        \n",
    "        for el in train:\n",
    "            \n",
    "            for i in range(len(el)-1):\n",
    "                \n",
    "                A[self.state_index[el[i][1]]][self.state_index[el[i+1][1]]] += 1\n",
    "                    \n",
    "        for i in range(A.shape[0]):\n",
    "            A[i] /= np.sum(A[i])\n",
    "                \n",
    "        return A\n",
    "    \n",
    "    # transition matrix for second order HMM\n",
    "    def trans_proba_2(self, train):\n",
    "        \n",
    "        A = np.zeros((self.N**2,self.N))\n",
    "        \n",
    "        for el in train:\n",
    "            \n",
    "            for i in range(len(el) - 2):\n",
    "                # we encode the N**2 values by the formula l1*26 + l2, \n",
    "                # with l1 and l2 the indices of the first and second letters  \n",
    "                A[self.state_index[el[i][1]]*(len(self.state_list)) + self.state_index[el[i+1][1]]][self.state_index[el[i+2][1]]] += 1\n",
    "        \n",
    "        for i in range(A.shape[0]):\n",
    "            if(np.sum(A[i]) != 0):\n",
    "                A[i] /= np.sum(A[i])\n",
    "                \n",
    "        return A\n",
    "    \n",
    "    # emission matrix\n",
    "    def emission_proba(self, train):\n",
    "        \n",
    "        B = np.zeros((self.N,self.M))\n",
    "        \n",
    "        flat = list(itertools.chain.from_iterable(train))\n",
    "        \n",
    "        count = Counter(flat)\n",
    "        \n",
    "        for x in self.state_list:\n",
    "            for y in self.obs_list:\n",
    "                B[self.state_index[x]][self.obs_index[y]] = count[(x,y)]\n",
    "                \n",
    "        for i in range(self.N):\n",
    "            B[i] /= np.sum(B[i])\n",
    "            \n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viterbi for first order HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi(hmm,obs):\n",
    "    \n",
    "    # number of states\n",
    "    N = hmm.N\n",
    "    \n",
    "    # transition matrix\n",
    "    A = hmm.trans_proba\n",
    "    \n",
    "    # emission matrix\n",
    "    B = hmm.emission_proba\n",
    "    \n",
    "    # intial state proba\n",
    "    pi = hmm.init_state_proba\n",
    "    \n",
    "    state_index = hmm.state_index\n",
    "    \n",
    "    obs_index = hmm.obs_index\n",
    "    \n",
    "    index_obs = hmm.index_obs\n",
    "    \n",
    "    # matrix to reconstruct the most probable sequence\n",
    "    most_prob_seq = np.zeros((N,len(obs)))\n",
    "    \n",
    "    # fill the first column with values from 0 to N-1, not required just for the semantic \n",
    "    most_prob_seq[:,0] = np.arange(N)\n",
    "    \n",
    "    # calculate mu_1\n",
    "    mu = B[:,obs_index[obs[0]]]*pi\n",
    "    \n",
    "    \n",
    "    for k,i in enumerate(obs[1:]):\n",
    "        \n",
    "        # temporary variable to hold the values of mu\n",
    "        tmp = np.zeros(N)\n",
    "        \n",
    "        for j in hmm.state_list:\n",
    "            \n",
    "            vect = B[state_index[j],obs_index[i]]*A[:,state_index[j]]*mu\n",
    "            \n",
    "            tmp[state_index[j]] = np.max(vect)\n",
    "            \n",
    "            most_prob_seq[state_index[j]][k+1] = np.argmax(vect)\n",
    "            \n",
    "        mu = tmp\n",
    "        \n",
    "    seq = []\n",
    "    \n",
    "    seq.append(index_obs[np.argmax(mu)])\n",
    "    \n",
    "    # reconstruct the inverted path\n",
    "    for i in range(len(obs)-1,0,-1):\n",
    "    \n",
    "        seq.append(index_obs[most_prob_seq[obs_index[seq[len(obs) - 1 - i]],i]])\n",
    "        \n",
    "    # return the most probable sequence i.e. the non-inverted path \n",
    "    return seq[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viterbi for second order HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi_2(hmm,obs):\n",
    "    \n",
    "    if(len(obs) <= 2 ):\n",
    "        return Viterbi(hmm,obs)\n",
    "    # number of states\n",
    "    N = hmm.N\n",
    "    \n",
    "    # transition matrix for second order HMM\n",
    "    A = hmm.trans_proba_2\n",
    "\n",
    "    \n",
    "    # emission matrix\n",
    "    B = hmm.emission_proba\n",
    "    \n",
    "    # intial state proba\n",
    "    pi = hmm.init_state_proba\n",
    "    \n",
    "    state_index = hmm.state_index\n",
    "    \n",
    "    obs_index = hmm.obs_index\n",
    "    \n",
    "    index_obs = hmm.index_obs\n",
    "    \n",
    "    \n",
    "    # list of matrices to reconstruct the most probable sequence\n",
    "    c = []\n",
    "        \n",
    "    # calculate d_1\n",
    "    d1 = B[:,obs_index[obs[0]]]*pi\n",
    "    \n",
    "    # calculate d_2\n",
    "    \n",
    "    d = d1[:,None]*hmm.trans_proba*B[:,obs_index[obs[1]]]\n",
    "    \n",
    "    toN = np.arange(N)\n",
    "    \n",
    "    for i in obs[2:]:\n",
    "        \n",
    "        # temporary variable to hold the values of mu\n",
    "        tmp_d = np.zeros((N,N))\n",
    "        tmp_c = np.zeros((N,N))\n",
    "        \n",
    "        for m,_ in enumerate(hmm.state_list):\n",
    "            \n",
    "            for n,_ in enumerate(hmm.state_list):\n",
    "                \n",
    "                vect = d[:,m]*A[toN*N + m, n]\n",
    "                \n",
    "                tmp_d[m,n] = np.max(vect)*B[n,obs_index[i]]\n",
    "                \n",
    "                tmp_c[m,n] = np.argmax(vect)\n",
    "        \n",
    "        d = tmp_d\n",
    "        \n",
    "        c.append(tmp_c)\n",
    "    \n",
    "    k = len(obs)\n",
    "    seq = np.zeros(k, dtype = np.int8)\n",
    "    \n",
    "    x,y = np.unravel_index(d.argmax(), d.shape)\n",
    "    \n",
    "    seq[k-1] = y\n",
    "    seq[k-2] = x\n",
    "    \n",
    "    for i,j in zip(range(k-3,-1,-1),range(len(c)-1,-1,-1)):\n",
    "        \n",
    "        seq[i] = c[j][seq[i+1],seq[i+2]]\n",
    "    \n",
    "    output = []\n",
    "    for i in range(len(seq)):\n",
    "        output.append(index_obs[seq[i]])\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(true,test,pred):\n",
    "    \n",
    "    pos = 0\n",
    "    \n",
    "    neg = 0\n",
    "    \n",
    "    l1 = list(itertools.chain.from_iterable(true))\n",
    "    \n",
    "    l2 = list(itertools.chain.from_iterable(test))\n",
    "    \n",
    "    l3 = list(itertools.chain.from_iterable(pred))\n",
    "    \n",
    "    for i in range(len(l1)):\n",
    "        \n",
    "        if(l1[i] != l2[i] and l1[i] == l3[i]):\n",
    "            pos +=1\n",
    "            \n",
    "        if(l1[i] == l2[i] and l1[i] != l3[i]):\n",
    "            neg +=1\n",
    "            \n",
    "    return pos,neg,(np.array(l1) != np.array(l2)).sum()\n",
    "\n",
    "def accuracy(true,pred):\n",
    "    \n",
    "    l1 = np.array(list(itertools.chain.from_iterable(true)))\n",
    "        \n",
    "    l2 = np.array(list(itertools.chain.from_iterable(pred)))\n",
    "    \n",
    "    return (l1 == l2).sum()/l1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(training,testing,f,first_order = True):\n",
    "    \n",
    "    hmm = HMM(training)\n",
    "    test = []\n",
    "    true = []\n",
    "    for l in testing:\n",
    "        test.append([el[0] for el in l])\n",
    "        true.append([el[1] for el in l])\n",
    "\n",
    "    pred = []\n",
    "\n",
    "    for el in test:\n",
    "        pred.append(f(hmm,el))\n",
    "        \n",
    "    pos,neg,over = eval(true,test,pred)\n",
    "    maxlen = len(list(itertools.chain.from_iterable(true)))\n",
    "\n",
    "    if(first_order):\n",
    "        print(\"First order HMM made {} mistakes over {} and corrected {} mistakes over {} characters\".format(neg,maxlen-over,pos,over))\n",
    "    else:\n",
    "        print(\"Second order HMM made {} mistakes over {} and corrected {} mistakes over {} characters\".format(neg,maxlen-over,pos,over))\n",
    "    \n",
    "    print(\"The overall accuracy is about {0:.2f}%\".format(accuracy(true,pred)*100))\n",
    "    \n",
    "    print(\"Without doing anything, the accuracy is about {0:.2f}%\".format(accuracy(true,test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Testing Viterbi for first order HMM with 10% error__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First order HMM made 79 mistakes over 6575 and corrected 247 mistakes over 745 characters\n",
      "The overall accuracy is about 92.12%\n",
      "Without doing anything, the accuracy is about 89.82%\n"
     ]
    }
   ],
   "source": [
    "results(train_10,test_10,Viterbi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Testing Viterbi for second order HMM with 10% error__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second order HMM made 129 mistakes over 6575 and corrected 448 mistakes over 745 characters\n",
      "The overall accuracy is about 94.18%\n",
      "Without doing anything, the accuracy is about 89.82%\n"
     ]
    }
   ],
   "source": [
    "results(train_10,test_10,Viterbi_2,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Testing Viterbi for first order HMM with 20% error__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First order HMM made 363 mistakes over 13452 and corrected 1080 mistakes over 3239 characters\n",
      "The overall accuracy is about 84.89%\n",
      "Without doing anything, the accuracy is about 80.59%\n"
     ]
    }
   ],
   "source": [
    "results(train_20,test_20,Viterbi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Testing Viterbi for second order HMM with 20% error__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second order HMM made 524 mistakes over 13452 and corrected 1919 mistakes over 3239 characters\n",
      "The overall accuracy is about 88.95%\n",
      "Without doing anything, the accuracy is about 80.59%\n"
     ]
    }
   ],
   "source": [
    "results(train_20,test_20,Viterbi_2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
